{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Model-1 which converts English text to Hinglish using SKAndMl/english-to-hinglish pre trained model."
      ],
      "metadata": {
        "id": "4K3Vp_Wf2f1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9UsaqzqkeUr",
        "outputId": "c92d82ac-052e-46af-9c4b-10de6df85974"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYv7CdtRncJ2",
        "outputId": "9c324235-8e1c-443a-91a9-9deed6a22c8a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"SkAndMl/english-to-hinglish\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"SkAndMl/english-to-hinglish\")\n",
        "\n",
        "text=\":I had about a 30 minute demo just using this new headset\"\n",
        "text1=\" Definitely share your feedback in the comment section.\"\n",
        "text2=\" So even if it's a big video, I will clearly mention all the products.\"\n",
        "text3=\" I was waiting for my bag.\"\n",
        "\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs)\n",
        "\n",
        "translation = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "\n",
        "print(translation)\n",
        "inputs = tokenizer(text1, return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs)\n",
        "\n",
        "translation = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "\n",
        "print(translation)\n",
        "inputs = tokenizer(text2, return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs)\n",
        "\n",
        "translation = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "\n",
        "print(translation)\n",
        "inputs = tokenizer(text3, return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs)\n",
        "\n",
        "translation = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "\n",
        "print(translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56dyG85ZrGAF",
        "outputId": "4c668608-1415-48c7-b2ac-0bea6f3488a1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ": mujhe is new headset ka istemaal karke 30 minute ka abhi lagaye\n",
            "sabse aapke supers in the scription mein share karta hai...................................................................\n",
            "To ye bahut bada video hai, to main sabhi productions ke baare mein baat kar sakta hoon.\n",
            "main mere bag ke liye wait kar raha tha.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model-2 which converts them in hindi text with mbart-large-50-one-to-many-mmt pre trained model"
      ],
      "metadata": {
        "id": "4caFpsYR2WjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze | grep transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAJPpgGhr1f2",
        "outputId": "7fb93397-88fb-4ff0-e56e-71a12bca5c34"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers==4.35.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n"
      ],
      "metadata": {
        "id": "-59iAWWIr3N7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\")\n",
        "\n"
      ],
      "metadata": {
        "id": "VhlmOECPr41Z"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=\" I had about a 30 minute demo just using this new headset\"\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\", src_lang=\"en_XX\")\n",
        "model_inputs = tokenizer(text, return_tensors=\"pt\")\n"
      ],
      "metadata": {
        "id": "Cah-QWGmr6vs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# translate from English to Hindi\n",
        "generated_tokens = model.generate(\n",
        "    **model_inputs,\n",
        "    forced_bos_token_id=tokenizer.lang_code_to_id[\"hi_IN\"]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "UXdD9NiGsEfd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "translation"
      ],
      "metadata": {
        "id": "BghE58WZSuBO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08b42f28-f727-4d98-ab4a-6d3e269b2420"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['मैं सिर्फ इस नए हेडसेट के उपयोग के बारे में एक 30 मिनट डेमो था']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Definitely share your feedback in the comment section\"\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\", src_lang=\"en_XX\")\n",
        "model_inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "# translate from English to Hindi\n",
        "generated_tokens = model.generate(\n",
        "    **model_inputs,\n",
        "    forced_bos_token_id=tokenizer.lang_code_to_id[\"hi_IN\"]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "XaTdP0TVvNb4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "translation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eM94Mz7a0l_m",
        "outputId": "e85879a6-1d7b-4443-83fa-15830cdb090d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['निश्चित रूप से अपनी प्रतिक्रिया को टिप्पणी सेक्शन में साझा करें']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"So even if it's a big video, I will clearly mention all the products.\"\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\", src_lang=\"en_XX\")\n",
        "model_inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "# translate from English to Hindi\n",
        "generated_tokens = model.generate(\n",
        "    **model_inputs,\n",
        "    forced_bos_token_id=tokenizer.lang_code_to_id[\"hi_IN\"]\n",
        ")\n",
        "\n",
        "translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "translation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15M6CmDU0pMl",
        "outputId": "a87ce368-6e1e-4493-a461-ade38b5c3ffa"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['तो अगर यह एक बड़ा वीडियो है, मैं स्पष्ट रूप से सभी उत्पादों का उल्लेख करेंगे।']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"I was waiting for my bag.\"\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\", src_lang=\"en_XX\")\n",
        "model_inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "# translate from English to Hindi\n",
        "generated_tokens = model.generate(\n",
        "    **model_inputs,\n",
        "    forced_bos_token_id=tokenizer.lang_code_to_id[\"hi_IN\"]\n",
        ")\n",
        "\n",
        "translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "translation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh85PngJ05tG",
        "outputId": "470f5f64-ded0-4089-d56e-35743d601cda"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['मैं अपने बैग की प्रतीक्षा कर रहा था।']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PIZdMRMd1HCM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}